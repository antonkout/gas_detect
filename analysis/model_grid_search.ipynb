{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(files):\n",
    "    '''\n",
    "    Prepare features and labels for a binary classification task based on a dataset of files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - files (list of str): A list of file paths representing the dataset. Each file is associated with a data sample.\n",
    "    '''\n",
    "\n",
    "    selfeatures1 = [file for file in files if \"gas\" in file.split('/',-1)[-1]]\n",
    "    selfeatures1.sort()\n",
    "    selfeatures2 = [file for file in files if \"non\" in file.split('/',-1)[-1]]\n",
    "    random.shuffle(selfeatures2)\n",
    "    selfeatures2 = selfeatures2[:len(selfeatures1)]\n",
    "    selfeatures = selfeatures1 + selfeatures2\n",
    "\n",
    "    X = np.asarray([np.load(feature, mmap_mode='r')['arr_0'].flatten() for feature in selfeatures])\n",
    "    y = np.asarray([1] * len(selfeatures1) + [0] * len(selfeatures2))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_train_sgdclassifier(X, y, param_grid):\n",
    "    '''\n",
    "    Train an SGDClassifier using grid search to find the best hyperparameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - X (numpy.ndarray): Features of the dataset.\n",
    "    - y (numpy.ndarray): Labels corresponding to the features (1 for positive, 0 for negative).\n",
    "    - param_grid (dict): Hyperparameter grid to search for the best configuration.\n",
    "    '''\n",
    "    best_estimator = None  \n",
    "    sgdclassifier = SGDClassifier(\n",
    "                                penalty = 'l2', #'l1'\n",
    "                                loss = 'hinge', #'log_loss', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'\n",
    "                                learning_rate='adaptive', \n",
    "                                shuffle=True, \n",
    "                                early_stopping = False,\n",
    "                                tol = 1e-3,\n",
    "                                validation_fraction = 0.2,\n",
    "                                n_jobs=1)\n",
    "\n",
    "        \n",
    "    grid_search = GridSearchCV(sgdclassifier, param_grid, scoring='f1_macro', cv=1, n_jobs=2, verbose=0, return_train_score=True) \n",
    "    grid_search.fit(X, y)\n",
    "        \n",
    "    if best_estimator is None or grid_search.best_score_ > best_estimator.best_score_:\n",
    "        best_estimator = grid_search\n",
    "\n",
    "    return best_estimator.best_estimator_, best_estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(clf, X_valid, y_valid):\n",
    "    '''\n",
    "    Calculate various classification metrics for a given classifier's predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - clf: Classifier model for which metrics need to be calculated.\n",
    "    - X_valid (numpy.ndarray): Features of the validation dataset.\n",
    "    - y_valid (numpy.ndarray): True labels for the validation dataset.\n",
    "    '''\n",
    "\n",
    "    print(f\"Metrics Calculation\")\n",
    "    print(f\"-------------------\")\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    \n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    precision = precision_score(y_valid, y_pred)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    roc_auc = roc_auc_score(y_valid, y_pred)\n",
    "    print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "    print()\n",
    "\n",
    "    class_report = classification_report(y_valid, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"/home/antonkout/Documents/modules/flammable_gas_detection/release/data/dataset/propane/dataset_arrays_hof/training\"\n",
    "path_test = \"/home/antonkout/Documents/modules/flammable_gas_detection/release/data/dataset/propane/dataset_arrays_hof/test\"\n",
    "\n",
    "trainfeatures = [str(file) for file in Path(path_train).rglob('*') if file.is_file()]\n",
    "testfeatures = [str(file) for file in Path(path_test).rglob('*') if file.is_file()]\n",
    "\n",
    "X_train, y_train = prepare_features(trainfeatures)\n",
    "\n",
    "param_grid = {\n",
    "        'alpha' : [0.1],\n",
    "        'eta0': [0.1,],\n",
    "        'max_iter': [3000, 3200],\n",
    "    }\n",
    "\n",
    "sgd_classifier, best_param = gridsearch_train_sgdclassifier(X_train, y_train, param_grid)\n",
    "print(\"Best parameters found from grid search:\")\n",
    "print(best_param)\n",
    "print()\n",
    "X_test, y_test = prepare_features(testfeatures)\n",
    "calculate_metrics(sgd_classifier, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the parameters of the classifier\n",
    "classifier_params = sgd_classifier.get_params()\n",
    "\n",
    "# Convert the parameters to a JSON string\n",
    "classifier_params_json = json.dumps(classifier_params, indent=4)\n",
    "with open('./classifier_params.json', 'w') as json_file:\n",
    "    json_file.write(classifier_params_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gas-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
